{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from edward.models import (\n",
    "    Categorical, Dirichlet, Empirical, InverseGamma,\n",
    "    MultivariateNormalDiag, Normal, ParamMixture, Bernoulli, PointMass, Mixture)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class dataset(object):\n",
    "    def __init__(self, N, M, D1, D2, K=2):\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        self.D1 = D1\n",
    "        self.D2 = D2\n",
    "        self.K = K\n",
    "        self.Z = np.zeros((N,D1), dtype=np.float32)\n",
    "        self.X = np.zeros((N,D2), dtype=np.float32)\n",
    "        self.Y = np.zeros((N,1))\n",
    "        self.C = np.zeros((N,1), dtype=np.float32)\n",
    "        self.beta = None\n",
    "        self.mus = None\n",
    "        self.stds = None\n",
    "        self.WX = None\n",
    "        self.WY = None\n",
    "        self.sigmaX = None\n",
    "        \n",
    "    def create(self):\n",
    "#         beta = np.random.dirichlet([1]*self.M)\n",
    "        beta = [1/self.M]*self.M\n",
    "        mus = np.random.randn(self.M, self.D1)*4\n",
    "        stds = [[1]*self.D1]*self.M\n",
    "        WX = np.random.randn(self.D1, self.D2)\n",
    "        if self.K == 2:\n",
    "            WY = np.random.randn(self.D1)\n",
    "        else:\n",
    "            WY = np.random.randn(self.D1, self.K)\n",
    "        sigmaX = [1]*self.D2\n",
    "        \n",
    "        for n in range(self.N):\n",
    "            c = np.argmax(np.random.multinomial(1, beta))\n",
    "            self.C[n,:] = c\n",
    "            self.Z[n, :] = np.random.multivariate_normal(mus[c], np.diag(stds[c]))\n",
    "            self.X[n, :] = np.random.multivariate_normal(np.matmul(self.Z[n],WX), np.diag(sigmaX))\n",
    "            if self.K == 2:\n",
    "                self.Y[n,:] = np.random.binomial(1,1/(1+np.exp(-np.matmul(self.Z[n],WY))))\n",
    "            else:\n",
    "                uprob = np.exp(np.matmul(self.Z[n],WY))\n",
    "                self.Y[n,:] = np.argmax(np.random.multinomial(1,uprob/np.sum(uprob)))\n",
    "                del uprob\n",
    "\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.mus = mus\n",
    "        self.stds = stds\n",
    "        self.WX = WX\n",
    "        self.WY = WY\n",
    "        self.sigmaX = sigmaX\n",
    "\n",
    "    def print_params(self):\n",
    "        print(\"Cluster Probabilities:\", self.beta)\n",
    "        print(\"Centers:\")\n",
    "        Xcenters = np.matmul(self.mus, self.WX)\n",
    "        for i in range(self.M):\n",
    "            print(i,self.mus[i,:],Xcenters[i,:])\n",
    "        for i in range(self.M):\n",
    "            classcounts = np.unique(self.Y[np.where(self.C==i)],return_counts=True)\n",
    "#             print(classcounts[1], classcounts[1][1]/(classcounts[1][0]+classcounts[1][1]))\n",
    "            print(i,classcounts)\n",
    "            \n",
    "        \n",
    "    def visualize(self):\n",
    "        color = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "        marker = ['x','+','0']\n",
    "        for i in [0,1]:\n",
    "            classpoints = np.where(self.Y==i)\n",
    "            for j in range(self.M):\n",
    "                points = np.where(self.C[classpoints]==j)\n",
    "                Z = self.Z[classpoints[0],:]\n",
    "                plt.plot(Z[points, 0], Z[points, 1], color[j]+marker[i])\n",
    "#                 plt.axis([-20,20,-20,20])\n",
    "                plt.title(\"Simulated dataset\")\n",
    "        plt.show()\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for i in [0,1]:\n",
    "            classpoints = np.where(self.Y==i)\n",
    "            for j in range(self.M):\n",
    "                points = np.where(self.C[classpoints]==j)\n",
    "                X = self.X[classpoints[0],:]\n",
    "                plt.scatter(X[points, 0], X[points, 1], X[points,2],c=color[j], marker=marker[i])\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    def MAPdiagnostics(self, mode='print', qmu=None, qwx=None, qwy=None, Xtest=None, Ytest=None, K=2, k=2):\n",
    "        sess = ed.get_session()\n",
    "#         clusterprobs = sess.run(qbeta.params)\n",
    "        zproto = sess.run(qmu.params)\n",
    "        weightx = sess.run(qwx.params)\n",
    "        weighty = sess.run(qwy.params)\n",
    "        xcenters = np.matmul(zproto,weightx.transpose())\n",
    "        if K == 2:\n",
    "            ycenters = 1/(1+np.exp(-np.matmul(zproto,weighty.transpose())))\n",
    "        else:\n",
    "            uprob = np.exp(np.matmul(zproto,weighty.transpose()))\n",
    "            ycenters = uprob/np.expand_dims(np.sum(uprob, axis=1), axis=1)\n",
    "            del uprob\n",
    "        \n",
    "        if mode=='print':\n",
    "            print(\"Inferred prototypes axes:\")\n",
    "            data.print_params()\n",
    "            print(\"__________________________________________\\n\")\n",
    "            for i in range(zproto.shape[0]):\n",
    "                print(i,zproto[i,:],ycenters[i,:],xcenters[i,:])\n",
    "        \n",
    "        elif mode=='evaluate':\n",
    "            print(k)\n",
    "            invWx = np.linalg.pinv(weightx)\n",
    "            ztest = np.matmul(Xtest, invWx.transpose())\n",
    "            if K == 2:\n",
    "                ymat = 1/(1+np.exp(-np.matmul(ztest,weighty.transpose())))\n",
    "            else:\n",
    "                uprob = np.exp(np.matmul(ztest,weighty.transpose()))\n",
    "                ymat = uprob/np.expand_dims(np.sum(uprob, axis=1), axis=1)\n",
    "                del uprob\n",
    "                \n",
    "            nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(zproto)\n",
    "            distances, indices = nbrs.kneighbors(ztest)\n",
    "            invdist = np.reciprocal(distances)\n",
    "            probdist = invdist/np.expand_dims(invdist.sum(axis=1), axis=1)\n",
    "            \n",
    "            if K==2:\n",
    "                ynn = np.zeros([Xtest.shape[0],1])\n",
    "            else:\n",
    "                ynn = np.zeros([Xtest.shape[0],K])\n",
    "                countnn = 0\n",
    "                countmat = 0\n",
    "            \n",
    "            for i in range(Xtest.shape[0]):\n",
    "                for j in range(k):\n",
    "                    ynn[i] = ynn[i]+ycenters[indices[i,j]]*probdist[i,j]\n",
    "                if K > 2:\n",
    "                    if np.argmax(ynn[i])==Ytest[i]:\n",
    "                        countnn = countnn + 1\n",
    "                    if np.argmax(ymat[i])==Ytest[i]:\n",
    "                        countmat = countmat + 1\n",
    "#             for i in range(Xtest.shape[0]):\n",
    "#                 print(Ytest[i],ymat[i],ynn[i])\n",
    "            total = ynn.shape[0]\n",
    "            if K == 2:\n",
    "                print(np.sum((ynn>0.5)==Ytest)/total,np.sum((ymat>0.5)==Ytest)/total)\n",
    "                print(roc_auc_score(Ytest,ynn), roc_auc_score(Ytest,ymat),\"\\n\")\n",
    "            else:\n",
    "                print(countnn/total, countmat/total)\n",
    "            \n",
    "\n",
    "    def EMdiagnostics(self, qmu=None, qwx=None, qwy=None, qz=None):\n",
    "        sess = ed.get_session()\n",
    "        probs = sess.run(qc.probs)\n",
    "        cluster = np.argmax(probs, axis=1)\n",
    "        clusterlabels = np.zeros([self.M, 10])\n",
    "        for i in range(self.M):\n",
    "            temp = Ytrain[np.where(cluster==i)]\n",
    "            elem, count = np.unique(temp, return_counts=True)\n",
    "            elem = elem.astype(int)\n",
    "            for j in range(elem.shape[0]):\n",
    "                clusterlabels[i,elem[j]] = count[j]\n",
    "\n",
    "        zproto = sess.run(qmu.mean())\n",
    "        dictionary = sess.run(qwx.mean())\n",
    "        dictionary = np.matmul(zproto,dictionary.transpose())*Xscale+Xmean\n",
    "        # np.place(dictionary, dictionary<0, 0)\n",
    "        for i in range(dictionary.shape[0]):\n",
    "            print(clusterlabels[i,:].astype(int))\n",
    "            utils.show(dictionary[i,:].reshape((28,28)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "M = 2\n",
    "D1 = 2\n",
    "D2 = 3\n",
    "K = 3\n",
    "inference = 'EM'\n",
    "model = 'collapsed'\n",
    "initialization = 'kmeans'\n",
    "experiment = 'new'\n",
    "\n",
    "data = dataset(N, M, D1, D2, K)\n",
    "\n",
    "if experiment == 'new':\n",
    "    data.create()\n",
    "else:\n",
    "    with open('dataset.pkl','rb') as infile:\n",
    "        data = pickle.load(infile)\n",
    "# data.visualize()\n",
    "N = 750\n",
    "Xtrain = data.X[:N]\n",
    "Ytrain = data.Y[:N]\n",
    "Xtest = data.X[N:]\n",
    "Ytest = data.Y[N:]\n",
    "Ytrain = Ytrain[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model != \"collapsed\":\n",
    "    beta = Dirichlet(tf.ones(M))\n",
    "    mu = Normal(tf.zeros(D1), tf.ones(D1), sample_shape=M)\n",
    "    sigmasq = InverseGamma(tf.ones(D1), tf.ones(D1), sample_shape=M)\n",
    "    z = ParamMixture(beta, {'loc': mu, 'scale_diag': tf.sqrt(sigmasq)},\n",
    "                     MultivariateNormalDiag,\n",
    "                     sample_shape=N)\n",
    "    c = z.cat\n",
    "    wx = Normal(loc=tf.zeros([D2, D1]), scale=tf.ones([D2, D1]))\n",
    "    x = Normal(loc=tf.matmul(z, wx, transpose_b=True), scale=tf.ones([N, D2]))\n",
    "    if K == 2:\n",
    "        wy = Normal(loc=tf.zeros([1, D1]), scale=tf.ones([1, D1]))\n",
    "        y = Bernoulli(logits=tf.matmul(z, wy, transpose_b=True))\n",
    "    else:\n",
    "        wy = Normal(loc=tf.zeros([K, D1]), scale=tf.ones([K, D1]))\n",
    "        y = Categorical(logits=tf.matmul(z, wy, transpose_b=True))\n",
    "else:\n",
    "    beta = Dirichlet(tf.ones(M))\n",
    "    mu = Normal(tf.zeros(D1), tf.ones(D1), sample_shape=M)\n",
    "    sigmasq = InverseGamma(tf.ones(D1), tf.ones(D1), sample_shape=M)\n",
    "    cat = Categorical(probs=beta, sample_shape=N)\n",
    "    components = [\n",
    "    MultivariateNormalDiag(mu[k], sigmasq[k], sample_shape=N)\n",
    "    for k in range(M)]\n",
    "    z = Mixture(cat=cat, components=components,sample_shape=N)\n",
    "    wx = Normal(loc=tf.zeros([D2, D1]), scale=tf.ones([D2, D1]))\n",
    "    x = Normal(loc=tf.matmul(z, wx, transpose_b=True), scale=tf.ones([N, D2]))\n",
    "    if K == 2:\n",
    "        wy = Normal(loc=tf.zeros([1, D1]), scale=tf.ones([1, D1]))\n",
    "        y = Bernoulli(logits=tf.matmul(z, wy, transpose_b=True))\n",
    "    else:\n",
    "        wy = Normal(loc=tf.zeros([K, D1]), scale=tf.ones([K, D1]))\n",
    "        y = Categorical(logits=tf.matmul(z, wy, transpose_b=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if inference == 'VI':\n",
    "    qz = Normal(loc=tf.Variable(tf.random_normal([N, D1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([N, D1]))))\n",
    "    qmu = Normal(loc=tf.Variable(tf.random_normal([M, D1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([M, D1]))))\n",
    "    qwx = Normal(loc=tf.Variable(tf.random_normal([D2, D1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([D2, D1]))))\n",
    "    qwy = Normal(loc=tf.Variable(tf.random_normal([1, D1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([1, D1]))))\n",
    "#     qc = Categorical(logits=tf.Variable(tf.zeros([N,M])))\n",
    "\n",
    "    # inference = ed.MAP([mu,c], data={x: data.X, y: data.Y})\n",
    "    inference = ed.KLqp({mu: qmu}, data={x: data.X, y: data.Y})\n",
    "    #  , z: qz, wy: qwy, wx: qwx\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "    inference.run(n_iter=500, n_print=100, n_samples=50,optimizer=optimizer)\n",
    "\n",
    "    \n",
    "if inference == 'MAP':\n",
    "    qz = PointMass(params=tf.Variable(tf.random_normal([N, D1])))\n",
    "    qmu = PointMass(params=tf.Variable(tf.random_normal([M, D1])))\n",
    "    qwx = PointMass(params=tf.Variable(tf.random_normal([D2, D1])))\n",
    "    \n",
    "    if K == 2:\n",
    "        qwy = PointMass(params=tf.Variable(tf.random_normal([1, D1])))\n",
    "    else:\n",
    "        qwy = PointMass(params=tf.Variable(tf.random_normal([K, D1])))\n",
    "        \n",
    "    qsigmasq = PointMass(params=tf.Variable(tf.ones([M,D1])))\n",
    "    qc = PointMass(params=tf.Variable(tf.zeros(N)))\n",
    "    inference = ed.MAP({mu:qmu, wx:qwx, wy:qwy, sigmasq:qsigmasq}, data={x: data.X, y: data.Y})\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "    inference.run(n_iter=5000, n_print=100, optimizer=optimizer)\n",
    "\n",
    "\n",
    "if inference == 'EM':\n",
    "    \n",
    "    qz = Normal(loc=tf.Variable(tf.random_normal([N, D1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([N, D1]))))\n",
    "#     qc = Categorical(logits=tf.Variable(tf.zeros([N,M])))\n",
    "#     qbeta = PointMass(params=tf.Variable(tf.ones(M)/M))\n",
    "    wxinit = np.random.normal(size=[D2, D1]).astype(np.float32)\n",
    "    qwx = PointMass(params=tf.Variable(wxinit))\n",
    "    \n",
    "    if K == 2:\n",
    "        qwy = PointMass(params=tf.Variable(tf.random_normal([1, D1])))\n",
    "    else:\n",
    "        qwy = PointMass(params=tf.Variable(tf.random_normal([K, D1])))\n",
    "        \n",
    "    qsigmasq = PointMass(params=tf.Variable(tf.ones([M,D1])))\n",
    "    if initialization == 'random':\n",
    "        qmu = PointMass(params=tf.Variable(tf.random_normal([M, D1])))\n",
    "    elif initialization == 'kmeans':\n",
    "        kmeans = KMeans(n_clusters=M, random_state=0, n_init=5, n_jobs=-2).fit(Xtrain)\n",
    "        xinit = kmeans.cluster_centers_\n",
    "        zinit = np.matmul(xinit, np.linalg.pinv(wxinit).transpose()).astype(np.float32)\n",
    "        qmu = PointMass(params=tf.Variable(zinit))\n",
    "            \n",
    "    \n",
    "    inference_e = ed.KLqp({z:qz}, data={x: Xtrain, y: Ytrain, mu:qmu, wx:qwx, wy:qwy, sigmasq:qsigmasq})\n",
    "    inference_m = ed.MAP({mu:qmu, wx:qwx, wy:qwy, sigmasq:qsigmasq}, data={x: Xtrain, y: Ytrain, z:qz})\n",
    "    inference_e.initialize(optimizer = tf.train.AdamOptimizer(learning_rate=1e-3))\n",
    "    inference_m.initialize()\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    init.run()\n",
    "    \n",
    "    for i in range(500):\n",
    "        for j in range(5):\n",
    "            info_dict_e = inference_e.update()\n",
    "        info_dict_m = inference_m.update()\n",
    "        inference_m.print_progress(info_dict_m)\n",
    "\n",
    "        \n",
    "if inference == 'MCMC':\n",
    "    T = 2000  # number of MCMC samples\n",
    "    qz = Empirical(tf.Variable(tf.zeros([T, N, D1])))\n",
    "    qmu = Empirical(tf.Variable(tf.zeros([T, M, D1])))\n",
    "    qsigmasq = Empirical(tf.Variable(tf.ones([T, M, D1])))\n",
    "    qwx = Empirical(tf.Variable(tf.random_normal([T, D2, D1])))\n",
    "    qwy = Empirical(tf.Variable(tf.random_normal([T, 1, D1])))\n",
    "    inference = ed.Gibbs({mu: qmu, sigmasq: qsigmasq}, data={x: data.X, y:data.Y})\n",
    "    inference.initialize()\n",
    "\n",
    "    sess = ed.get_session()\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    t_ph = tf.placeholder(tf.int32, [])\n",
    "    running_cluster_means = tf.reduce_mean(qmu.params[:t_ph], 0)\n",
    "    running_weight_means = tf.reduce_mean(qwx.params[:t_ph], 0)\n",
    "\n",
    "    for _ in range(inference.n_iter):\n",
    "      info_dict = inference.update()\n",
    "      inference.print_progress(info_dict)\n",
    "      t = info_dict['t']\n",
    "      if t % inference.n_print == 0:\n",
    "        print(\"\\nInferred cluster means:\")\n",
    "        print(sess.run(tf.matmul(running_cluster_means, running_weight_means, transpose_b=True), {t_ph: t - 1}))\n",
    "    data.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in [1]:\n",
    "    data.MAPdiagnostics('print', qmu, qwx, qwy, Xtest, Ytest, K, k)\n",
    "# print(np.sum(np.argmax(sess.run(qc.probs), axis=1)==data.C[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z_post = ed.copy(z, {c: qc, mu: qmu})\n",
    "# z_gen = sess.run(z_post)\n",
    "# plt.scatter(z_gen[:,0], z_gen[:, 1])\n",
    "# plt.show()\n",
    "\n",
    "# x_post = ed.copy(x, {wx: qwx, z: qz, c: qc, wy: qwy, mu: qmu})\n",
    "# x_gen = sess.run(x_post)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# plt.scatter(x_gen[:,0], x_gen[:, 1], x_gen[:,2])\n",
    "# plt.show()\n",
    "\n",
    "# print(ed.evaluate('log_likelihood', data={x_post: data.X}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dataset1.pkl', 'wb') as infile:\n",
    "    pickle.dump(data, infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for k in [1,2,4,8,16]:\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(Xtrain, Ytrain[:,0])\n",
    "    print(k,np.sum(neigh.predict(Xtest)==Ytest[:,0])/Ytest.shape[0],roc_auc_score(Ytest, neigh.predict_proba(Xtest)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
