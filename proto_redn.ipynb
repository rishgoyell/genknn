{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.models import (\n",
    "    Categorical, Dirichlet, Empirical, InverseGamma,\n",
    "    MultivariateNormalDiag, Normal, ParamMixture, Bernoulli, PointMass)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class dataset(object):\n",
    "    def __init__(self, N, M, D1, D2):\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        self.D1 = D1\n",
    "        self.D2 = D2\n",
    "        self.Z = np.zeros((N,D1), dtype=np.float32)\n",
    "        self.X = np.zeros((N,D2), dtype=np.float32)\n",
    "        self.Y = np.zeros((N,1))\n",
    "        self.C = np.zeros((N,1), dtype=np.float32)\n",
    "        self.beta = None\n",
    "        self.mus = None\n",
    "        self.stds = None\n",
    "        self.WX = None\n",
    "        self.WY = None\n",
    "        self.sigmaX = None\n",
    "        \n",
    "    def create(self):\n",
    "        beta = np.random.dirichlet([1]*self.M)\n",
    "        mus = np.random.randn(self.M, self.D1)*4\n",
    "        stds = [[1, 1]]*self.M\n",
    "        WX = np.random.randn(self.D1, self.D2)\n",
    "        WY = np.random.randn(self.D1)\n",
    "        sigmaX = [1,1,1]\n",
    "        \n",
    "        for n in range(self.N):\n",
    "            c = np.argmax(np.random.multinomial(1, beta))\n",
    "            self.C[n,:] = c\n",
    "            self.Z[n, :] = np.random.multivariate_normal(mus[c], np.diag(stds[c]))\n",
    "            self.X[n, :] = np.random.multivariate_normal(np.matmul(self.Z[n],WX), np.diag(sigmaX))\n",
    "            self.Y[n,:] = np.random.binomial(1,1/(1+np.exp(-np.matmul(self.Z[n],WY))))\n",
    "\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.mus = mus\n",
    "        self.stds = stds\n",
    "        self.WX = WX\n",
    "        self.WY = WY\n",
    "        self.sigmaX = sigmaX\n",
    "\n",
    "    def print_params(self):\n",
    "        print(\"Cluster Probabilities:\", self.beta)\n",
    "        print(\"Centers:\")\n",
    "        for i in range(self.M):\n",
    "            print(self.mus[i,:])\n",
    "        print(\"X-Centers:\")\n",
    "        Xcenters = np.matmul(self.mus, self.WX)\n",
    "        for i in range(Xcenters.shape[0]):\n",
    "            print(Xcenters[i,:])\n",
    "            \n",
    "        \n",
    "    def visualize(self):\n",
    "        color = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "        marker = ['x','+','0']\n",
    "        for i in [0,1]:\n",
    "            classpoints = np.where(self.Y==i)\n",
    "            for j in range(self.M):\n",
    "                points = np.where(self.C[classpoints]==j)\n",
    "                Z = self.Z[classpoints[0],:]\n",
    "                plt.plot(Z[points, 0], Z[points, 1], color[j]+marker[i])\n",
    "#                 plt.axis([-20,20,-20,20])\n",
    "                plt.title(\"Simulated dataset\")\n",
    "        plt.show()\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for i in [0,1]:\n",
    "            classpoints = np.where(self.Y==i)\n",
    "            for j in range(self.M):\n",
    "                points = np.where(self.C[classpoints]==j)\n",
    "                X = self.X[classpoints[0],:]\n",
    "                plt.scatter(X[points, 0], X[points, 1], X[points,2],c=color[j], marker=marker[i])\n",
    "        plt.show()\n",
    "\n",
    "    def MAPdiagnostics(self, qmu=None, qwx=None, qwy=None, qc=None):\n",
    "        sess = ed.get_session()\n",
    "        print(\"Inferred prototypes axes:\")\n",
    "        data.print_params()\n",
    "        print(\"________________________\\n\")\n",
    "        zproto = sess.run(qmu.params)\n",
    "        weightx = sess.run(qwx.params)\n",
    "#         weighty = sess.run(qwy.params)\n",
    "        xcenters = np.matmul(zproto,weightx.transpose())\n",
    "        for i in range(zproto.shape[0]):\n",
    "            print(i, zproto[i,:],xcenters[i,:])\n",
    "\n",
    "    def VIdiagnostics(self, qmu=None, qwx=None, qwy=None, qc=None):\n",
    "        sess = ed.get_session()\n",
    "        probs = sess.run(qc.probs)\n",
    "        cluster = np.argmax(probs, axis=1)\n",
    "        clusterlabels = np.zeros([self.M, 10])\n",
    "        for i in range(self.M):\n",
    "            temp = Ytrain[np.where(cluster==i)]\n",
    "            elem, count = np.unique(temp, return_counts=True)\n",
    "            elem = elem.astype(int)\n",
    "            for j in range(elem.shape[0]):\n",
    "                clusterlabels[i,elem[j]] = count[j]\n",
    "\n",
    "        zproto = sess.run(qmu.mean())\n",
    "        dictionary = sess.run(qwx.mean())\n",
    "        dictionary = np.matmul(zproto,dictionary.transpose())*Xscale+Xmean\n",
    "        # np.place(dictionary, dictionary<0, 0)\n",
    "        for i in range(dictionary.shape[0]):\n",
    "            print(clusterlabels[i,:].astype(int))\n",
    "            utils.show(dictionary[i,:].reshape((28,28)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 3000\n",
    "M = 3\n",
    "D1 = 2\n",
    "D2 = 3\n",
    "inference = 'EM'\n",
    "data = dataset(N, M, D1, D2)\n",
    "data.create()\n",
    "data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta = Dirichlet(tf.ones(M))\n",
    "mu = Normal(tf.zeros(D1), tf.ones(D1), sample_shape=M)\n",
    "sigmasq = InverseGamma(tf.ones(D1), tf.ones(D1), sample_shape=M)\n",
    "z = ParamMixture(beta, {'loc': mu, 'scale_diag': tf.sqrt(sigmasq)},\n",
    "                 MultivariateNormalDiag,\n",
    "                 sample_shape=N)\n",
    "c = z.cat\n",
    "wx = Normal(loc=tf.zeros([D2, D1]), scale=tf.ones([D2, D1]))\n",
    "wy = Normal(loc=tf.zeros([1, D1]), scale=tf.ones([1, D1]))\n",
    "x = Normal(loc=tf.matmul(z, wx, transpose_b=True), scale=tf.ones([N, D2]))\n",
    "y = Bernoulli(logits=tf.matmul(z, wy, transpose_b=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if inference == 'VI':\n",
    "    qz = Normal(loc=tf.Variable(tf.random_normal([N, D1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([N, D1]))))\n",
    "    qmu = Normal(loc=tf.Variable(tf.random_normal([M, D1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([M, D1]))))\n",
    "    qwx = Normal(loc=tf.Variable(tf.random_normal([D2, D1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([D2, D1]))))\n",
    "    qwy = Normal(loc=tf.Variable(tf.random_normal([1, D1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([1, D1]))))\n",
    "    qc = Categorical(logits=tf.Variable(tf.zeros([N,M])))\n",
    "\n",
    "    # inference = ed.MAP([mu,c], data={x: data.X, y: data.Y})\n",
    "    inference = ed.KLqp({mu: qmu, c: qc}, data={x: data.X, y: data.Y})\n",
    "    #  , z: qz, wy: qwy, wx: qwx\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "    inference.run(n_iter=500, n_print=100, n_samples=50,optimizer=optimizer)\n",
    "\n",
    "    \n",
    "if inference == 'MAP':\n",
    "    qz = PointMass(params=tf.Variable(tf.random_normal([N, D1])))\n",
    "    qmu = PointMass(params=tf.Variable(tf.random_normal([M, D1])))\n",
    "    qwx = PointMass(params=tf.Variable(tf.random_normal([D2, D1])))\n",
    "    qwy = PointMass(params=tf.Variable(tf.random_normal([1, D1])))\n",
    "    qsigmasq = PointMass(params=tf.Variable(tf.ones([M,D1])))\n",
    "    qc = PointMass(params=tf.Variable(tf.zeros(N)))\n",
    "    inference = ed.MAP({mu:qmu, wx:qwx, wy:qwy, sigmasq:qsigmasq}, data={x: data.X, y: data.Y})\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "    inference.run(n_iter=5000, n_print=100, optimizer=optimizer)\n",
    "\n",
    "\n",
    "if inference == 'EM':\n",
    "    qz = Normal(loc=tf.Variable(tf.random_normal([N, D1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([N, D1]))))\n",
    "    qc = Categorical(logits=tf.Variable(tf.zeros([N,M])))\n",
    "    qmu = PointMass(params=tf.Variable(tf.random_normal([M, D1])))\n",
    "    qwx = PointMass(params=tf.Variable(tf.random_normal([D2, D1])))\n",
    "    qwy = PointMass(params=tf.Variable(tf.random_normal([1, D1])))\n",
    "    qsigmasq = PointMass(params=tf.Variable(tf.ones([M,D1])))\n",
    "    \n",
    "    inference_e = ed.KLqp({z:qz}, data={x: data.X, y: data.Y, mu:qmu, wx:qwx, wy:qwy, sigmasq:qsigmasq})\n",
    "    inference_m = ed.MAP({mu:qmu, wx:qwx, wy:qwy, sigmasq:qsigmasq}, data={x: data.X, y: data.Y, z:qz})\n",
    "    inference_e.initialize(optimizer = tf.train.AdamOptimizer(learning_rate=1e-3))\n",
    "    inference_m.initialize()\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    init.run()\n",
    "    \n",
    "    for i in range(1000):\n",
    "        for j in range(20):\n",
    "            info_dict_e = inference_e.update()\n",
    "        info_dict_m = inference_m.update()\n",
    "        inference_m.print_progress(info_dict_m)\n",
    "\n",
    "        \n",
    "if inference == 'MCMC':\n",
    "    T = 2000  # number of MCMC samples\n",
    "    qz = Empirical(tf.Variable(tf.zeros([T, N, D1])))\n",
    "    qmu = Empirical(tf.Variable(tf.zeros([T, M, D1])))\n",
    "    qsigmasq = Empirical(tf.Variable(tf.ones([T, M, D1])))\n",
    "    qwx = Empirical(tf.Variable(tf.random_normal([T, D2, D1])))\n",
    "#     qwy = Empirical(tf.Variable(tf.random_normal([T, 1, D1])))\n",
    "    inference = ed.Gibbs({mu: qmu, sigmasq: qsigmasq}, data={x: data.X, y:data.Y})\n",
    "    inference.initialize()\n",
    "\n",
    "    sess = ed.get_session()\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    t_ph = tf.placeholder(tf.int32, [])\n",
    "    running_cluster_means = tf.reduce_mean(qmu.params[:t_ph], 0)\n",
    "    running_weight_means = tf.reduce_mean(qwx.params[:t_ph], 0)\n",
    "\n",
    "    for _ in range(inference.n_iter):\n",
    "      info_dict = inference.update()\n",
    "      inference.print_progress(info_dict)\n",
    "      t = info_dict['t']\n",
    "      if t % inference.n_print == 0:\n",
    "        print(\"\\nInferred cluster means:\")\n",
    "        print(sess.run(tf.matmul(running_cluster_means, running_weight_means, transpose_b=True), {t_ph: t - 1}))\n",
    "    data.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.MAPdiagnostics(qmu, qwx, qwy)\n",
    "# print(np.sum(np.argmax(sess.run(qc.probs), axis=1)==data.C[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z_post = ed.copy(z, {c: qc, mu: qmu})\n",
    "# z_gen = sess.run(z_post)\n",
    "# plt.scatter(z_gen[:,0], z_gen[:, 1])\n",
    "# plt.show()\n",
    "\n",
    "# x_post = ed.copy(x, {wx: qwx, z: qz, c: qc, wy: qwy, mu: qmu})\n",
    "# x_gen = sess.run(x_post)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# plt.scatter(x_gen[:,0], x_gen[:, 1], x_gen[:,2])\n",
    "# plt.show()\n",
    "\n",
    "# print(ed.evaluate('log_likelihood', data={x_post: data.X}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('abc.pkl', 'wb') as infile:\n",
    "#     pickle.dump(data, infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
